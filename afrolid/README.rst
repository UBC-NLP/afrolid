AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems


GitHub link: `https://github.com/UBC-NLP/afrolid <https://github.com/UBC-NLP/afrolid>`__

Online demo link: `https://demos.dlnlp.ai/afrolid <https://demos.dlnlp.ai/afrolid/>`__ 


Getting Started
---------------

The `full documentation <https://afrolid.readthedocs.io/en/latest/>`__
contains instructions for getting started, translation using diffrent methods, intergrate AfroLID with your code, and provides more examples.


License
-------

afrolid(-py) is Apache-2.0 licensed. The license applies to the pre-trained models as well.

Citation
--------

If you use AfroLID toolkit or the pre-trained models for your
scientific publication, or if you find the resources in this repository
useful, please cite our paper as follows:

::
  @article{adebara2022afrolid,
  title={AfroLID: A Neural Language Identification Tool for African Languages},
  author={Adebara, Ife and Elmadany, AbdelRahim and Abdul-Mageed, Muhammad and Inciarte, Alcides Alcoba},
  booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
  month = December,
  year = "2022",
}

7. Acknowledgments
------------------

We gratefully acknowledge support from the Natural Sciences and Engineering Research Council of Canada (NSERC; RGPIN-2018-04267), the Social Sciences and Humanities Research Council of Canada (SSHRC; 435-2018-0576; 895-2020-1004; 895-2021-1008),  `The Digital Research Alliance of Canada (the Alliance) <www.alliancecan.ca/en>`__ and `UBC
ARC-Sockeye <https://doi.org/10.14288/SOCKEYE>`__ and Advanced Micro Devices, Inc. (AMD). Any opinions, conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of NSERC, SSHRC, CFI, CC, AMD, or UBC ARC-Sockeye. 
